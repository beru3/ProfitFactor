#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ›œæ—¥åˆ¥ãƒ»é«˜æœŸå¾…å€¤ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆé¸å®šã‚·ã‚¹ãƒ†ãƒ  - Pythonç‰ˆ
è¦ä»¶å®šç¾©æ›¸ã«åŸºã¥ã„ãŸåˆ†æãƒ­ã‚¸ãƒƒã‚¯ + æŒ‡å®šãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå‡ºåŠ›

ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹æˆ:
- main.py (ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«)
- é€±åˆŠã‚¢ãƒãƒãƒªãƒ¼FXãƒ¬ãƒãƒ¼ãƒˆ_YYYYå¹´MMæœˆDDæ—¥ - åˆ†æãƒ¬ãƒãƒ¼ãƒˆ.csv (ãƒ¬ãƒãƒ¼ãƒˆ1)
- ã‚¢ãƒãƒãƒªãƒ¼FXãƒã‚¤ãƒ³ãƒˆåˆ¥æç›Šæ˜ç´° - ãƒã‚¤ãƒ³ãƒˆåˆ¥æç›Šæ˜ç´°(ä¸Šä½20ä½).csv (ãƒ¬ãƒãƒ¼ãƒˆ2)
- {åŸºæº–æ—¥}/ (å®Ÿè¡Œæ™‚ã«ä½œæˆã€CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç§»å‹•)
- output_{åŸºæº–æ—¥}.txt (åˆ†æçµæœå‡ºåŠ›)
"""

import os
import shutil
import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Any
import logging
import csv
import traceback
import re
import sys

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class FXAnalysisEngine:
    """FXæ›œæ—¥åˆ¥ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆé¸å®šã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, analysis_weeks: int = 26, pf_threshold: float = 1.3, max_results: int = 20):
        """
        åˆæœŸåŒ–
        
        Args:
            analysis_weeks: åˆ†æå¯¾è±¡æœŸé–“ï¼ˆé€±æ•°ï¼‰
            pf_threshold: ãƒ—ãƒ­ãƒ•ã‚£ãƒƒãƒˆãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼é–¾å€¤
            max_results: æœ€å¤§è¡¨ç¤ºä»¶æ•°ï¼ˆå„æ›œæ—¥ãƒ»å„ãƒ‘ã‚¿ãƒ¼ãƒ³ã”ã¨ã®è¡¨ç¤ºãƒã‚¤ãƒ³ãƒˆæ•°ï¼‰
        """
        self.settings = {
            'analysis_weeks': analysis_weeks,
            'pf_threshold': pf_threshold,
            'max_results': max_results  # å„æ›œæ—¥ãƒ»å„ãƒ‘ã‚¿ãƒ¼ãƒ³ã”ã¨ã®æœ€å¤§è¡¨ç¤ºä»¶æ•°
        }
        
        # è©•ä¾¡ãƒ‘ã‚¿ãƒ¼ãƒ³ã®åç§°ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆãƒ¬ãƒãƒ¼ãƒˆ1 â†’ ãƒ¬ãƒãƒ¼ãƒˆ2ï¼‰
        self.pattern_mapping = {
            'å‹ç‡é‡è¦–ãƒã‚¤ãƒ³ãƒˆ': 'å‹ç‡é‡è¦–ãƒã‚¤ãƒ³ãƒˆ',
            'åˆ©ç›ŠåŠ¹ç‡ãƒã‚¤ãƒ³ãƒˆ': 'åˆ©ç›ŠåŠ¹ç‡_STD_ãƒã‚¤ãƒ³ãƒˆ',
            'æ™‚é–“åŠ¹ç‡ãƒã‚¤ãƒ³ãƒˆ': 'æ™‚é–“åŠ¹ç‡ãƒã‚¤ãƒ³ãƒˆ',
            'æœ€å¤§åˆ©ç›Šãƒã‚¤ãƒ³ãƒˆ': 'æœ€å¤§åˆ©ç›Šãƒã‚¤ãƒ³ãƒˆ',
            'å‹ç‡é‡è¦–ãƒã‚¤ãƒ³ãƒˆUS': 'å‹ç‡é‡è¦–ãƒã‚¤ãƒ³ãƒˆUS',
            'åˆ©ç›ŠåŠ¹ç‡ãƒã‚¤ãƒ³ãƒˆUS': 'åˆ©ç›ŠåŠ¹ç‡_STD_ãƒã‚¤ãƒ³ãƒˆUS',
            'æ™‚é–“åŠ¹ç‡ãƒã‚¤ãƒ³ãƒˆUS': 'æ™‚é–“åŠ¹ç‡ãƒã‚¤ãƒ³ãƒˆUS',
            'æœ€å¤§åˆ©ç›Šãƒã‚¤ãƒ³ãƒˆUS': 'æœ€å¤§åˆ©ç›Šãƒã‚¤ãƒ³ãƒˆUS'
        }
        
        # å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆç”¨ã®è©•ä¾¡ãƒ‘ã‚¿ãƒ¼ãƒ³è¡¨ç¤ºå
        self.pattern_display_names = {
            'åˆ©ç›ŠåŠ¹ç‡ãƒã‚¤ãƒ³ãƒˆ': 'â—¾ï¸ğŸåˆ©ç›ŠåŠ¹ç‡',
            'å‹ç‡é‡è¦–ãƒã‚¤ãƒ³ãƒˆ': 'â—¾ï¸ğŸŸå‹ç‡é‡è¦–', 
            'æ™‚é–“åŠ¹ç‡ãƒã‚¤ãƒ³ãƒˆ': 'â—¾ï¸â°æ™‚é–“åŠ¹ç‡',
            'æœ€å¤§åˆ©ç›Šãƒã‚¤ãƒ³ãƒˆ': 'â—¾ï¸ğŸ¦æœ€å¤§åˆ©ç›Š'
        }
        
        # åŸºæœ¬4ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆUSã¯é™¤å¤–ï¼‰
        self.target_patterns = ['åˆ©ç›ŠåŠ¹ç‡ãƒã‚¤ãƒ³ãƒˆ', 'å‹ç‡é‡è¦–ãƒã‚¤ãƒ³ãƒˆ', 'æ™‚é–“åŠ¹ç‡ãƒã‚¤ãƒ³ãƒˆ', 'æœ€å¤§åˆ©ç›Šãƒã‚¤ãƒ³ãƒˆ']
        
    def find_csv_files(self, base_date: str) -> Tuple[str, str]:
        """
        æŒ‡å®šãƒ‘ã‚¿ãƒ¼ãƒ³ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
        
        Args:
            base_date: åŸºæº–æ—¥
            
        Returns:
            (ãƒ¬ãƒãƒ¼ãƒˆ1ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹, ãƒ¬ãƒãƒ¼ãƒˆ2ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹)
        """
        # åŸºæº–æ—¥ã‹ã‚‰ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåã‚’ç”Ÿæˆ
        base_dir = f"{base_date}"
        
        if not os.path.exists(base_dir):
            raise FileNotFoundError(f"åŸºæº–æ—¥ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {base_dir}")
        
        # å›ºå®šã®ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ä½¿ç”¨
        report1_file = os.path.join(base_dir, "é€±åˆŠã‚¢ãƒãƒãƒªãƒ¼FXãƒ¬ãƒãƒ¼ãƒˆ_2025å¹´06æœˆ22æ—¥ - åˆ†æãƒ¬ãƒãƒ¼ãƒˆ.csv")
        report2_file = os.path.join(base_dir, "ã‚¢ãƒãƒãƒªãƒ¼FXãƒã‚¤ãƒ³ãƒˆåˆ¥æç›Šæ˜ç´° - ãƒã‚¤ãƒ³ãƒˆåˆ¥æç›Šæ˜ç´°(ä¸Šä½20ä½).csv")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
        if not os.path.exists(report1_file):
            raise FileNotFoundError(f"ãƒ¬ãƒãƒ¼ãƒˆ1ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {report1_file}")
        if not os.path.exists(report2_file):
            raise FileNotFoundError(f"ãƒ¬ãƒãƒ¼ãƒˆ2ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {report2_file}")
        
        logger.info(f"CSVãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢å®Œäº†: report1={report1_file}, report2={report2_file}")
        return report1_file, report2_file

    def load_csv_files(self, base_date: str) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """
        CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        
        Args:
            base_date: åŸºæº–æ—¥
            
        Returns:
            (ãƒ¬ãƒãƒ¼ãƒˆ1ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ , ãƒ¬ãƒãƒ¼ãƒˆ2ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ )
        """
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢
            report1_file, report2_file = self.find_csv_files(base_date)
            
            # ãƒ¬ãƒãƒ¼ãƒˆ1èª­ã¿è¾¼ã¿
            report1_df = pd.read_csv(report1_file, encoding='utf-8-sig')
            logger.info(f"ãƒ¬ãƒãƒ¼ãƒˆ1èª­ã¿è¾¼ã¿å®Œäº†: {len(report1_df)}è¡Œ")
            
            # ãƒ¬ãƒãƒ¼ãƒˆ2èª­ã¿è¾¼ã¿
            report2_df = pd.read_csv(report2_file, encoding='utf-8-sig')
            logger.info(f"ãƒ¬ãƒãƒ¼ãƒˆ2èª­ã¿è¾¼ã¿å®Œäº†: {len(report2_df)}è¡Œ")
            
            return report1_df, report2_df
            
        except Exception as e:
            logger.error(f"CSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
            raise
    
    def create_directory_and_move_files(self, base_date: str, report1_file: str, report2_file: str) -> str:
        """
        åŸºæº–æ—¥ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆã—ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç§»å‹•
        
        Args:
            base_date: åŸºæº–æ—¥
            report1_file: ãƒ¬ãƒãƒ¼ãƒˆ1ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            report2_file: ãƒ¬ãƒãƒ¼ãƒˆ2ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            
        Returns:
            ä½œæˆã—ãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹
        """
        # æ—¢ã«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯ä½•ã‚‚ã—ãªã„
        directory = base_date
        if os.path.exists(directory):
            logger.info(f"ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™: {directory}")
            return directory
            
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        os.makedirs(directory, exist_ok=True)
        logger.info(f"ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆã—ã¾ã—ãŸ: {directory}")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ç§»å‹•ï¼ˆæ—¢ã«ç§»å‹•æ¸ˆã¿ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ï¼‰
        for file_path in [report1_file, report2_file]:
            if not file_path.startswith(directory):
                filename = os.path.basename(file_path)
                new_path = os.path.join(directory, filename)
                shutil.copy2(file_path, new_path)
                logger.info(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼ã—ã¾ã—ãŸ: {file_path} -> {new_path}")
        
        return directory
    
    def filter_analysis_period(self, report2_df: pd.DataFrame, weeks: int) -> pd.DataFrame:
        """
        åˆ†æå¯¾è±¡æœŸé–“ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        
        Args:
            report2_df: ãƒ¬ãƒãƒ¼ãƒˆ2ã®DataFrame
            weeks: åˆ†æå¯¾è±¡æœŸé–“ï¼ˆé€±æ•°ï¼‰
            
        Returns:
            ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã•ã‚ŒãŸDataFrame
        """
        cutoff_date = datetime.now() - timedelta(weeks=weeks)
        report2_df['å–å¼•æ—¥'] = pd.to_datetime(report2_df['å–å¼•æ—¥'])
        filtered_df = report2_df[report2_df['å–å¼•æ—¥'] >= cutoff_date]
        logger.info(f"åˆ†æå¯¾è±¡æœŸé–“: {weeks}é€±é–“, ãƒ•ã‚£ãƒ«ã‚¿å¾Œãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {len(filtered_df)}ä»¶")
        return filtered_df
    
    def extract_points_from_report1(self, report1_df: pd.DataFrame) -> List[Dict[str, Any]]:
        """
        ãƒ¬ãƒãƒ¼ãƒˆ1ã‹ã‚‰è©•ä¾¡ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¥ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒã‚¤ãƒ³ãƒˆã‚’æŠ½å‡º
        ã‚¯ãƒ­ã‚¹å††ï¼ˆJPYãƒšã‚¢ï¼‰ã®ã¿ã‚’å¯¾è±¡ã¨ã™ã‚‹
        
        Args:
            report1_df: ãƒ¬ãƒãƒ¼ãƒˆ1ã®DataFrame
            
        Returns:
            ãƒã‚¤ãƒ³ãƒˆæƒ…å ±ã®ãƒªã‚¹ãƒˆ
        """
        points = []
        
        for idx, row in report1_df.iterrows():
            # ã‚¯ãƒ­ã‚¹å††ï¼ˆJPYãƒšã‚¢ï¼‰ã®ã¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            currency = str(row['éŠ˜æŸ„'])  # æ–‡å­—åˆ—ã«å¤‰æ›
            if not (currency.endswith('JPY') or currency.startswith('JPY')):
                continue
                
            for pattern in self.target_patterns:
                if pattern in row and pd.notna(row[pattern]):
                    ranking = float(row[pattern])
                    if 1 <= ranking <= 20:
                        # æ—¥æ–¹å‘ã‚«ãƒ©ãƒ ãŒãªã„å ´åˆã¯æ–¹å‘ã‚«ãƒ©ãƒ ã‚’ä½¿ç”¨
                        day_direction = row.get('æ—¥æ–¹å‘', row['æ–¹å‘'])
                        
                        # ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆæ–‡å­—åˆ—ã‚’æµ®å‹•å°æ•°ç‚¹ã«å¤‰æ›ã™ã‚‹é–¢æ•°
                        def parse_percent(val):
                            if pd.isna(val):
                                return 0.0
                            if isinstance(val, str) and '%' in val:
                                return float(val.strip('%')) / 100.0
                            return float(val)
                        
                        point_info = {
                            'row_index': idx,
                            'point_name': pattern,
                            'report2_point_name': self.pattern_mapping[pattern],
                            'ranking': int(ranking),
                            'currency': currency,
                            'direction': row['æ–¹å‘'],
                            'entry_time': row['ã‚¨ãƒ³ãƒˆãƒªãƒ¼æ™‚åˆ»'],
                            'close_time': row['ã‚¯ãƒ­ãƒ¼ã‚ºæ™‚åˆ»'],
                            'details': f"{day_direction}_{currency}_{row['ã‚¨ãƒ³ãƒˆãƒªãƒ¼æ™‚åˆ»']}_{row['ã‚¯ãƒ­ãƒ¼ã‚ºæ™‚åˆ»']}",
                            'win_rate_30': parse_percent(row.get('å‹ç‡_30æ—¥', 0)),
                            'win_rate_90': parse_percent(row.get('å‹ç‡_90æ—¥', 0)),
                            'win_rate_365': parse_percent(row.get('å‹ç‡_365æ—¥', 0)),
                            'win_rate_avg': parse_percent(row.get('å‹ç‡_å¹³å‡', 0))
                        }
                        points.append(point_info)
        
        # ãƒ©ãƒ³ã‚­ãƒ³ã‚°é †ã§ã‚½ãƒ¼ãƒˆ
        points.sort(key=lambda x: x['ranking'])
        logger.info(f"ãƒ¬ãƒãƒ¼ãƒˆ1ã‹ã‚‰æŠ½å‡ºã—ãŸãƒã‚¤ãƒ³ãƒˆæ•°: {len(points)}ä»¶")
        logger.info(f"ã‚¯ãƒ­ã‚¹å††ï¼ˆJPYãƒšã‚¢ï¼‰ã®ã¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ã¾ã—ãŸ")
        return points
    
    def calculate_weekly_profit_factor(self, report2_df: pd.DataFrame, weeks: int) -> Dict[str, Any]:
        """
        æ›œæ—¥åˆ¥ãƒ—ãƒ­ãƒ•ã‚£ãƒƒãƒˆãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼è¨ˆç®—ï¼ˆç¬¬1æ¤œè¨¼ãƒ•ã‚§ãƒ¼ã‚ºï¼‰
        
        Args:
            report2_df: ãƒ¬ãƒãƒ¼ãƒˆ2ã®DataFrame
            weeks: åˆ†æå¯¾è±¡æœŸé–“ï¼ˆé€±æ•°ï¼‰
            
        Returns:
            æ›œæ—¥åˆ¥PFãƒ‡ãƒ¼ã‚¿æ§‹é€ 
        """
        filtered_df = self.filter_analysis_period(report2_df, weeks)
        weekly_pf = {}
        
        for _, row in filtered_df.iterrows():
            point_name = row['ãƒã‚¤ãƒ³ãƒˆå']
            day_of_week = row['å–å¼•æ—¥_æ›œæ—¥']
            point_value = int(row['ãƒã‚¤ãƒ³ãƒˆå€¤'])
            profit_pips = float(row['æç›Špipsã®SUM']) if pd.notna(row['æç›Špipsã®SUM']) else 0.0
            
            # ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®åˆæœŸåŒ–
            if point_name not in weekly_pf:
                weekly_pf[point_name] = {}
            if day_of_week not in weekly_pf[point_name]:
                weekly_pf[point_name][day_of_week] = {}
            if point_value not in weekly_pf[point_name][day_of_week]:
                weekly_pf[point_name][day_of_week][point_value] = {
                    'total_profit': 0.0,
                    'total_loss': 0.0,
                    'trades': 0,
                    'pf': 0.0,
                    'profit_pips': profit_pips
                }
            
            target = weekly_pf[point_name][day_of_week][point_value]
            target['trades'] += 1
            target['profit_pips'] = profit_pips
            
            if profit_pips > 0:
                target['total_profit'] += profit_pips
            else:
                target['total_loss'] += abs(profit_pips)
            
            # ãƒ—ãƒ­ãƒ•ã‚£ãƒƒãƒˆãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼è¨ˆç®—
            if target['total_loss'] == 0:
                target['pf'] = 999.9 if target['total_profit'] > 0 else 0
            else:
                target['pf'] = target['total_profit'] / target['total_loss']
        
        logger.info("æ›œæ—¥åˆ¥ãƒ—ãƒ­ãƒ•ã‚£ãƒƒãƒˆãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼è¨ˆç®—å®Œäº†")
        return weekly_pf
    
    def select_optimal_points(self, report1_points: List[Dict], weekly_pf: Dict) -> Dict[str, Dict]:
        """
        æ›œæ—¥åˆ¥æœ€é©ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆé¸å®šï¼ˆç¬¬2æ¤œè¨¼ãƒ•ã‚§ãƒ¼ã‚ºï¼‰
        
        Args:
            report1_points: ãƒ¬ãƒãƒ¼ãƒˆ1ã‹ã‚‰æŠ½å‡ºã—ãŸãƒã‚¤ãƒ³ãƒˆ
            weekly_pf: æ›œæ—¥åˆ¥PFãƒ‡ãƒ¼ã‚¿
            
        Returns:
            æ›œæ—¥åˆ¥æœ€é©ãƒã‚¤ãƒ³ãƒˆ
        """
        days_of_week = ['æœˆ', 'ç«', 'æ°´', 'æœ¨', 'é‡‘']
        results = {}
        
        for day in days_of_week:
            results[day] = {pattern: [] for pattern in self.target_patterns}
            
            for point in report1_points:
                point_name = point['report2_point_name']
                ranking = point['ranking']
                
                if (point_name in weekly_pf and 
                    day in weekly_pf[point_name] and 
                    ranking in weekly_pf[point_name][day]):
                    
                    ranking_data = weekly_pf[point_name][day][ranking]
                    
                    if ranking_data['pf'] >= self.settings['pf_threshold']:
                        optimal_point = {
                            'currency': point['currency'],
                            'entry_time': point['entry_time'],
                            'close_time': point['close_time'],
                            'direction': point['direction'],
                            'ranking': point['ranking'],
                            'profit_pips': ranking_data['profit_pips'],
                            'pf': ranking_data['pf'],
                            'trades': ranking_data['trades'],
                            'total_profit': ranking_data['total_profit'],
                            'total_loss': ranking_data['total_loss'],
                            'point_details': point
                        }
                        results[day][point['point_name']].append(optimal_point)
            
            # å„è©•ä¾¡ãƒ‘ã‚¿ãƒ¼ãƒ³ã§ã‚¨ãƒ³ãƒˆãƒªãƒ¼æ™‚é–“é †ã«ã‚½ãƒ¼ãƒˆ
            for pattern in self.target_patterns:
                # ã¾ãšPFé †ã«ã‚½ãƒ¼ãƒˆï¼ˆé™é †ï¼‰
                results[day][pattern].sort(key=lambda x: x['pf'], reverse=True)
                # PFé–¾å€¤ä»¥ä¸Šã®ãƒã‚¤ãƒ³ãƒˆã‚’æœ€å¤§è¡¨ç¤ºä»¶æ•°ã¾ã§é¸æŠ
                filtered_points = results[day][pattern][:self.settings['max_results']]
                
                # ã‚¨ãƒ³ãƒˆãƒªãƒ¼æ™‚é–“ã‚’æ•°å€¤åŒ–ã—ã¦æ¯”è¼ƒã™ã‚‹ãŸã‚ã®é–¢æ•°
                def time_to_minutes(time_str):
                    hours, minutes, seconds = map(int, time_str.split(':'))
                    # 0æ™‚å°ã¯24æ™‚å°ã¨ã—ã¦æ‰±ã†ï¼ˆæ—¥ä»˜ã‚’ã¾ãŸãã‚±ãƒ¼ã‚¹ï¼‰
                    if hours == 0:
                        hours = 24
                    return hours * 60 + minutes
                
                # é¸æŠã—ãŸãƒã‚¤ãƒ³ãƒˆã‚’ã‚¨ãƒ³ãƒˆãƒªãƒ¼æ™‚é–“é †ã«ã‚½ãƒ¼ãƒˆï¼ˆæ˜‡é †ï¼‰
                filtered_points.sort(key=lambda x: time_to_minutes(x['entry_time']))
                results[day][pattern] = filtered_points
        
        logger.info("æ›œæ—¥åˆ¥æœ€é©ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆé¸å®šå®Œäº†")
        return results
    
    def calculate_weekly_summary(self, day_results: Dict) -> Dict[str, float]:
        """
        é€±é–“åˆè¨ˆæç›Šè¨ˆç®—
        
        Args:
            day_results: æ›œæ—¥åˆ¥çµæœ
            
        Returns:
            é€±é–“åˆè¨ˆæç›Š
        """
        weekly_summary = {pattern: 0.0 for pattern in self.target_patterns}
        
        for day_data in day_results.values():
            for pattern in self.target_patterns:
                for point in day_data[pattern]:
                    weekly_summary[pattern] += point['profit_pips']
        
        logger.info("é€±é–“åˆè¨ˆæç›Šè¨ˆç®—å®Œäº†")
        return weekly_summary
    
    def format_results(self, optimal_points: Dict[str, Dict]) -> Dict[str, List[Dict]]:
        """
        çµæœã‚’å‡ºåŠ›ç”¨ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        
        Args:
            optimal_points: æ›œæ—¥åˆ¥æœ€é©ãƒã‚¤ãƒ³ãƒˆ
            
        Returns:
            ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¸ˆã¿çµæœ
        """
        formatted_results = {}
        days_of_week = ['æœˆ', 'ç«', 'æ°´', 'æœ¨', 'é‡‘']
        
        for day in days_of_week:
            formatted_results[day] = []
            
            for pattern, points in optimal_points[day].items():
                if points:
                    for point in points:
                        formatted_point = {
                            'é€šè²¨ãƒšã‚¢': point['currency'],
                            'ã‚¨ãƒ³ãƒˆãƒªãƒ¼': point['entry_time'],
                            'ã‚¯ãƒ­ãƒ¼ã‚º': point['close_time'],
                            'æ–¹å‘': point['direction'],
                            'é †ä½': point['ranking'],
                            'PF': f"{point['pf']:.2f}",
                            'çµæœ': '',
                            'pattern': pattern  # ãƒ‘ã‚¿ãƒ¼ãƒ³æƒ…å ±ã‚’è¿½åŠ 
                        }
                        formatted_results[day].append(formatted_point)
        
        logger.info("çµæœã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå®Œäº†")
        return formatted_results
    
    def save_output(self, formatted_results: Dict[str, List[Dict]], base_date: str) -> str:
        """
        çµæœã‚’CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        
        Args:
            formatted_results: ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¸ˆã¿çµæœ
            base_date: åŸºæº–æ—¥
            
        Returns:
            ä¿å­˜ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        output_file = f"output_{base_date}.csv"
        
        with open(output_file, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.writer(f)
            
            # åŸºæº–æ—¥ã®æƒ…å ±
            writer.writerow([f"{base_date}"])
            writer.writerow([])  # ç©ºè¡Œ
            
            # æ›œæ—¥åˆ¥ãƒ‡ãƒ¼ã‚¿
            day_names = {
                'æœˆ': 'æœˆæ›œæ—¥',
                'ç«': 'ç«æ›œæ—¥',
                'æ°´': 'æ°´æ›œæ—¥', 
                'æœ¨': 'æœ¨æ›œæ—¥',
                'é‡‘': 'é‡‘æ›œæ—¥'
            }
            
            # åŸºæº–æ—¥ã‹ã‚‰å„æ›œæ—¥ã®æ—¥ä»˜ã‚’è¨ˆç®—
            base_date_obj = datetime.strptime(base_date, '%Y-%m-%d')
            base_weekday = base_date_obj.weekday()  # 0=æœˆ, 1=ç«, 2=æ°´, 3=æœ¨, 4=é‡‘, 5=åœŸ, 6=æ—¥
            
            weekday_dates = {}
            weekday_map = {'æœˆ': 0, 'ç«': 1, 'æ°´': 2, 'æœ¨': 3, 'é‡‘': 4}
            
            # åŸºæº–æ—¥ãŒæ—¥æ›œæ—¥ã®å ´åˆã€ç¿Œæ—¥ï¼ˆæœˆæ›œæ—¥ï¼‰ã‹ã‚‰å§‹ã¾ã‚‹é€±ã‚’è¨ˆç®—
            if base_weekday == 6:  # æ—¥æ›œæ—¥
                for day, day_idx in weekday_map.items():
                    day_date = base_date_obj + timedelta(days=day_idx+1)
                    weekday_dates[day] = day_date.strftime('%Y/%m/%d')
            else:
                # åŸºæº–æ—¥ã®é€±ã®æœˆæ›œæ—¥ã‚’è¦‹ã¤ã‘ã‚‹
                monday = base_date_obj - timedelta(days=base_weekday)
                for day, day_idx in weekday_map.items():
                    day_date = monday + timedelta(days=day_idx)
                    weekday_dates[day] = day_date.strftime('%Y/%m/%d')
            
            # ãƒ‘ã‚¿ãƒ¼ãƒ³åã®è¡¨ç¤ºé †
            pattern_order = ['åˆ©ç›ŠåŠ¹ç‡ãƒã‚¤ãƒ³ãƒˆ', 'å‹ç‡é‡è¦–ãƒã‚¤ãƒ³ãƒˆ', 'æ™‚é–“åŠ¹ç‡ãƒã‚¤ãƒ³ãƒˆ', 'æœ€å¤§åˆ©ç›Šãƒã‚¤ãƒ³ãƒˆ']
            pattern_display = {
                'åˆ©ç›ŠåŠ¹ç‡ãƒã‚¤ãƒ³ãƒˆ': 'åˆ©ç›ŠåŠ¹ç‡',
                'å‹ç‡é‡è¦–ãƒã‚¤ãƒ³ãƒˆ': 'å‹ç‡é‡è¦–',
                'æ™‚é–“åŠ¹ç‡ãƒã‚¤ãƒ³ãƒˆ': 'æ™‚é–“åŠ¹ç‡',
                'æœ€å¤§åˆ©ç›Šãƒã‚¤ãƒ³ãƒˆ': 'æœ€å¤§åˆ©ç›Š'
            }
            
            for day in ['æœˆ', 'ç«', 'æ°´', 'æœ¨', 'é‡‘']:
                # æ›œæ—¥ã®å‰ã«ç©ºç™½è¡Œã‚’è¿½åŠ 
                writer.writerow([])
                
                # æ›œæ—¥ãƒ˜ãƒƒãƒ€ãƒ¼
                day_date = weekday_dates[day]
                writer.writerow(['', f"{day_names[day]}({day_date})"])
                
                # åˆ—ãƒ˜ãƒƒãƒ€ãƒ¼
                headers = ['é€šè²¨ãƒšã‚¢', 'ã‚¨ãƒ³ãƒˆãƒªãƒ¼', 'ã‚¯ãƒ­ãƒ¼ã‚º', 'æ–¹å‘', 'é †ä½', 'PF', 'çµæœ']
                header_row = ['']
                for pattern in pattern_order:
                    display_name = pattern_display[pattern]
                    header_row.extend([display_name, '', '', '', '', '', ''])
                writer.writerow(header_row)
                
                # åˆ—ãƒ˜ãƒƒãƒ€ãƒ¼ï¼ˆé …ç›®åï¼‰
                column_header = ['']
                for _ in range(4):  # 4ã¤ã®ãƒ‘ã‚¿ãƒ¼ãƒ³
                    column_header.extend(headers)
                writer.writerow(column_header)
                
                # ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¥ã«ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                pattern_data = {}
                for pattern in pattern_order:
                    pattern_data[pattern] = []
                    for point in formatted_results[day]:
                        if point.get('pattern') == pattern:
                            pattern_data[pattern].append(point)
                
                # æœ€å¤§è¡Œæ•°ã‚’è¨ˆç®—
                max_rows = max(len(pattern_data[pattern]) for pattern in pattern_order)
                
                # ãƒ‡ãƒ¼ã‚¿è¡Œ
                for i in range(max_rows):
                    row = [i + 1]
                    for pattern in pattern_order:
                        if i < len(pattern_data[pattern]):
                            point = pattern_data[pattern][i]
                            row.extend([
                                point.get('é€šè²¨ãƒšã‚¢', ''),
                                point.get('ã‚¨ãƒ³ãƒˆãƒªãƒ¼', ''),
                                point.get('ã‚¯ãƒ­ãƒ¼ã‚º', ''),
                                point.get('æ–¹å‘', ''),
                                point.get('é †ä½', ''),
                                point.get('PF', ''),
                                point.get('çµæœ', '')
                            ])
                        else:
                            row.extend(['', '', '', '', '', '', ''])
                    writer.writerow(row)
        
        logger.info(f"çµæœã‚’CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã—ã¾ã—ãŸ: {output_file}")
        return output_file
    
    def perform_analysis(self, base_date: str = None) -> Dict[str, Any]:
        """
        ãƒ¡ã‚¤ãƒ³åˆ†æå‡¦ç†
        
        Args:
            base_date: åŸºæº–æ—¥ï¼ˆYYYY-MM-DDå½¢å¼ï¼‰
            
        Returns:
            åˆ†æçµæœ
        """
        try:
            # 1. åŸºæº–æ—¥ã®è¨­å®š
            if base_date is None:
                base_date = self.get_base_date()
            
            # 2. CSVãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œç´¢
            report1_file, report2_file = self.find_csv_files(base_date)
            
            # 3. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
            report1_df, report2_df = self.load_csv_files(base_date)
            
            # 4. ãƒ¬ãƒãƒ¼ãƒˆ1ã‹ã‚‰ãƒã‚¤ãƒ³ãƒˆæŠ½å‡º
            report1_points = self.extract_points_from_report1(report1_df)
            
            # 5. ãƒ¬ãƒãƒ¼ãƒˆ2ã‹ã‚‰é€±é–“PFè¨ˆç®—
            weekly_pf = self.calculate_weekly_profit_factor(report2_df, self.settings['analysis_weeks'])
            
            # 6. æ›œæ—¥åˆ¥æœ€é©ãƒã‚¤ãƒ³ãƒˆé¸å®š
            day_results = self.select_optimal_points(report1_points, weekly_pf)
            
            # 7. çµæœã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
            formatted_results = self.format_results(day_results)
            
            # 8. ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
            output_file = self.save_output(formatted_results, base_date)
            
            # 9. ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆã¨ãƒ•ã‚¡ã‚¤ãƒ«ç§»å‹•
            created_dir = self.create_directory_and_move_files(base_date, report1_file, report2_file)
            
            # 10. å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ•´ç†
            self.organize_output_files(base_date, output_file)
            
            # 11. æ•´ç†å¾Œã®å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’æ›´æ–°
            output_file_path = os.path.join(created_dir, os.path.basename(output_file))
            
            return {
                'success': True,
                'base_date': base_date,
                'report1_file': report1_file,
                'report2_file': report2_file,
                'created_directory': created_dir,
                'output_file': output_file_path,
                'day_results': day_results,
                'weekly_summary': self.calculate_weekly_summary(day_results),
                'formatted_output': formatted_results,
                'stats': {
                    'report1_records': len(report1_df),
                    'report2_records': len(report2_df),
                    'extracted_points': len(report1_points),
                    'analysis_weeks': self.settings['analysis_weeks']
                }
            }
        except Exception as e:
            logger.error(f"åˆ†æå‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {
                'success': False,
                'error': str(e),
                'output_file': f"error_{base_date if base_date else 'unknown'}.log"
            }

    def get_base_date(self) -> str:
        """
        åŸºæº–æ—¥ã‚’å–å¾—
        
        Returns:
            åŸºæº–æ—¥ï¼ˆYYYY-MM-DDå½¢å¼ï¼‰
        """
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåã‹ã‚‰åŸºæº–æ—¥ã‚’å–å¾—
        dirs = [d for d in os.listdir() if os.path.isdir(d) and re.match(r'\d{4}-\d{2}-\d{2}', d)]
        
        if dirs:
            # æœ€æ–°ã®æ—¥ä»˜ã‚’ä½¿ç”¨
            latest_dir = max(dirs)
            return latest_dir
        else:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
            return "2025-06-22"

    def main(self) -> str:
        """
        ãƒ¡ã‚¤ãƒ³å‡¦ç†
        
        Returns:
            å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        try:
            # åˆ†æå®Ÿè¡Œ
            result = self.perform_analysis()
            
            # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’è¿”ã™
            return result['output_file']
            
        except Exception as e:
            logger.error(f"å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            logger.error(traceback.format_exc())
            raise

    def organize_output_files(self, base_date: str, output_file: str) -> None:
        """
        å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ•´ç†
        
        Args:
            base_date: åŸºæº–æ—¥
            output_file: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        directory = base_date
        
        # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒåŸºæº–æ—¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ãªã„å ´åˆã¯ç§»å‹•
        logger.info(f"å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®æ•´ç†ã‚’é–‹å§‹: {output_file}")
        
        if not output_file.startswith(directory):
            filename = os.path.basename(output_file)
            new_path = os.path.join(directory, filename)
            
            logger.info(f"å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç§»å‹•ã—ã¾ã™: {output_file} -> {new_path}")
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ—¢ã«å­˜åœ¨ã™ã‚‹å ´åˆã¯ä¸Šæ›¸ã
            if os.path.exists(new_path):
                os.remove(new_path)
                logger.info(f"æ—¢å­˜ã®å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã—ãŸ: {new_path}")
            
            # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼ã—ã¦å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
            shutil.copy2(output_file, new_path)
            logger.info(f"å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼ã—ã¾ã—ãŸ: {output_file} -> {new_path}")
            os.remove(output_file)
            logger.info(f"å…ƒã®å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã—ãŸ: {output_file}")
            
            # å…ƒã®ãƒ‘ã‚¹ã‚’æ›´æ–°
            output_file = new_path
        
        # å¤ã„txtãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
        txt_pattern = f"output_{base_date}.txt"
        if os.path.exists(txt_pattern):
            os.remove(txt_pattern)
            logger.info(f"å¤ã„txtãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã—ãŸ: {txt_pattern}")
        
        # åŸºæº–æ—¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®txtãƒ•ã‚¡ã‚¤ãƒ«ã‚‚å‰Šé™¤
        txt_pattern = os.path.join(directory, f"output_{base_date}.txt")
        if os.path.exists(txt_pattern):
            os.remove(txt_pattern)
            logger.info(f"å¤ã„txtãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã—ãŸ: {txt_pattern}")
            
        logger.info(f"å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®æ•´ç†ãŒå®Œäº†ã—ã¾ã—ãŸ")


def main():
    """
    ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
    """
    try:
        analyzer = FXAnalysisEngine()
        output_file = analyzer.main()
        print(f"åˆ†æå®Œäº†ã€‚çµæœã¯ {output_file} ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸã€‚")
        print("å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã¨å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã¯åŸºæº–æ—¥ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«æ•´ç†ã•ã‚Œã¾ã—ãŸã€‚")
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()